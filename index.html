<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Dominik Schnaus</title>

    <meta name="author" content="Dominik Schnaus">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="static/images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <meta property="og:title" content="Dominik Schnaus" />
    <meta property="og:locale" content="en_US" />
    <link rel="canonical" href="https://dominik-schnaus.github.io" />
    <meta property="og:url" content="https://dominik-schnaus.github.io" />
    <meta property="og:site_name" content="dominik-schnaus.github.io" />
    <meta property="og:type" content="website" />
    
    <meta name="google-site-verification" content="slMnCsrcKyRGwX72AVQDhXh5ouYKY5BzfY1mn52WpzA" /> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QQMNN9GSPS"></script>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-WJLLFB8X');</script>
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p class="name" style="text-align: center;">
                                        Dominik Schnaus
                                    </p>
                                    <p>
                                        I am passionate about <b>self-supervised learning</b>, <b>multi-modality</b>, and <b>generative models</b> in computer vision and beyond.
                                        Currently, I am pursuing my Ph.D. at the <a href="https://cvg.cit.tum.de/">Computer Vision Group</a> at TUM supervised by <a
                                            href="https://cvg.cit.tum.de/members/cremers">Prof. Daniel Cremers</a> under the lead of <a
                                            href="https://xiwang1212.github.io/homepage/">Dr. Xi Wang</a>.
                                        Before that, I completed my my M.Sc. in Mathematics in Data Science and my B.Sc. in Mathematics with a minor in Computer Science at <a href="https://www.tum.de/en/">TUM</a>.
                                    </p>
                                    <p style="text-align:center">
                                        <a href="mailto:dominik.schnaus@tum.de">Email</a> &nbsp;/&nbsp;
                                        <a href="https://scholar.google.com/citations?user=xIDDqOYAAAAJ&hl=en"
                                            target="_blank">Scholar</a> &nbsp;/&nbsp;
                                        <a href="https://www.linkedin.com/in/dominik-schnaus/" target="_blank">LinkedIn</a>
                                        &nbsp;/&nbsp;
                                        <a href="https://bsky.app/profile/schnaus.bsky.social" target="_blank">Bluesky</a>
                                        &nbsp;/&nbsp;
                                        <a href="https://github.com/dominik-schnaus" target="_blank">Github</a> &nbsp;/&nbsp;
                                        <a href="https://cvg.cit.tum.de/members/schnaus" target="_blank">Group
                                            Website</a>
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a href="static/images/dominik_schnaus.png"><img
                                            style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                                            alt="profile photo" src="static/images/dominik_schnaus.png" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Updates</h2>
                                    <p>
                                        <b>May 2025</b> The code for <a href="https://dominik-schnaus.github.io/itsamatch/">It's A (Blind) Match!</a> was released on <a href="https://github.com/dominik-schnaus/itsamatch">Github</a>.
                                    </p>
                                    <p>
                                        <b>March 2025</b> The pre-print of our new paper <a href="https://arxiv.org/pdf/2503.24129">It's A (Blind) Match!</a> is now online.
                                    </p>
                                    <p>
                                        <b>February 2025</b> <a href="https://dominik-schnaus.github.io/itsamatch/">It's A (Blind) Match!</a> was accepted at <b>CVPR 2025</b>.
                                    </p>
                                    <details>
                                    <summary><a>More updates</a>
                                    </summary>

                                    <p>
                                        <b>September 2023</b> The code for <a href="https://proceedings.mlr.press/v202/schnaus23a">Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</a> and <a href="http://bayesiandeeplearning.org/2021/papers/33.pdf">Kronecker-Factored Optimal Curvature</a> was released on <a href="https://github.com/DLR-RM/BPNN">Github</a>.
                                    </p>
                                    <p>
                                        <b>July 2023</b> The pre-print of our new paper <a href="https://arxiv.org/abs/2307.07753">Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</a> is now online.
                                    </p>
                                    <p>
                                        <b>April 2023</b> <a href="https://proceedings.mlr.press/v202/schnaus23a">Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</a> was accepted at <b>ICML 2023</b>.
                                    </p>
                                    <p>
                                        <b>April 2022</b> Started <b>Ph.D. in Computer Vision</b> at the <a href="https://cvg.cit.tum.de/">Computer Vision Group</a> at <b>TUM</b> supervised by <a
                                        href="https://cvg.cit.tum.de/members/cremers">Prof. Daniel Cremers</a>,
                                    </p>
                                    <p>
                                        <b>November 2021</b> <a href="http://bayesiandeeplearning.org/2021/papers/33.pdf">Kronecker-Factored Optimal Curvature</a> was accepted at the Bayesian Deep Learning Workshop at <b>NeurIPS 2022</b>.
                                    </p>
                                    <p>
                                        <b>October 2021</b> Finished <b>M.Sc. Mathematics in Data Science</b> at <b>TUM</b>.
                                    </p>
                                    <p>
                                        <b>October 2019</b> Started <b>M.Sc. Mathematics in Data Science</b> at <b>TUM</b>.
                                    </p>
                                    <p>
                                        <b>October 2019</b> Finished my <b>B.Sc. Mathematics</b> at <b>TUM</b>.
                                    </p>
                                    </details>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Publications</h2>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one"  onmouseout="itsamatch_stop()" onmouseover="itsamatch_start()">
                                        <div class="two" id='itsamatch_image'><video width=100% muted autoplay loop>
                                                <source src="itsamatch/static/videos/teaser.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video></div>
                                        <img src='itsamatch/static/images/teaser.png' width=100%>
                                    </div>
                                    <script type="text/javascript">
                                        function itsamatch_start() {
                                            document.getElementById('itsamatch_image').style.opacity = "1";
                                        }

                                        function itsamatch_stop() {
                                            document.getElementById('itsamatch_image').style.opacity = "0";
                                        }
                                        itsamatch_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                <a href="https://dominik-schnaus.github.io/itsamatch/">
                                    <span class="papertitle">It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data</span>
                                </a>
                                <br>
                                <strong>Dominik Schnaus</strong>,
                                <a href="https://arnike.github.io/" target="_blank">Nikita Araslanov</a>,
                                <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">Daniel Cremers</a>
                                <br>
                                <b>CVPR</b>, 2025
                                <br>
                                <a href="https://dominik-schnaus.github.io/itsamatch/" target="_blank">project page</a>
                                /
                                <a href="https://arxiv.org/pdf/2503.24129" target="_blank">paper</a>
                                /
                                <a href="https://arxiv.org/abs/2503.24129" target="_blank">arXiv</a>
                                /
                                <a href="https://github.com/dominik-schnaus/itsamatch" target="_blank">code</a>
                                <p></p>
                                <p>
                                    Vision-Language models need a lot of paired training data. Can we match vision and language without any supervision? Our work shows that it could be indeed feasible.
                                </p>
                            </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='static/images/koke2025on.png' width=100%>
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                <a href="https://openreview.net/pdf?id=X3OMHwfsxk">
                                    <span class="papertitle">On multi-scale Graph Representation Learning</span>
                                </a>
                                <br>
                                <a href="https://cvg.cit.tum.de/members/kchr" target="_blank">Christian Koke</a>,
                                <strong>Dominik Schnaus</strong>,
                                <a href="https://ysngshn.github.io/" target="_blank">Yuesong Shen</a>,
                                <a href="https://cvg.cit.tum.de/members/saroha" target="_blank">Abhishek Saroha</a>,
                                <a href="https://cvg.cit.tum.de/members/eisenber" target="_blank">Marvin Eisenberger</a>,
                                <a href="https://bastian.rieck.me/" target="_blank">Bastian Rieck</a>,
                                <a href="https://www.cs.ox.ac.uk/people/michael.bronstein/" target="_blank">Michael M Bronstein</a>,
                                <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">Daniel Cremers</a>
                                <br>
                                <b>LMRL at ICLR</b>, 2024
                                <br>
                                <a href="https://openreview.net/pdf?id=X3OMHwfsxk" target="_blank">paper</a>
                                <p></p>
                                <p>
                                    We show that existing graph neural networks struggle with graphs at different resolutions. We propose a modification of the message passing paradigm to overcome this issue.
                                </p>
                            </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='static/images/nouri2024ramp.png' width=100%>
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/solr.202400468">
                                    <span class="papertitle">Ramp Rate Metric Suitable for Solar Forecasting</span>
                                </a>
                                <br>
                                <a href="https://www.linkedin.com/in/bijan-nouri-664023218/" target="_blank">Bijan Nouri</a>,
                                <a href="https://www.linkedin.com/in/yann-fabel-b54165203/" target="_blank">Yann Fabel</a>,
                                Niklas Blum,
                                <strong>Dominik Schnaus</strong>,
                                Luis F. Zarzalejo,
                                Andreas Kazantzidis,
                                Stefan Wilbert
                                <br>
                                <b>Solar RRL</b>, 2024
                                <br>
                                <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/solr.202400468" target="_blank">paper</a>
                                <p></p>
                                <p>
                                    We propose a new ramp rate metric for solar irradiance forecasting.
                                </p>
                            </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='static/images/fabel2024combining.png' width=100%>
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/solr.202300808">
                                    <span class="papertitle">Combining Deep Learning and Physical Models: A Benchmark Study on All-Sky Imager-Based Solar Nowcasting Systems</span>
                                </a>
                                <br>
                                <a href="https://www.linkedin.com/in/yann-fabel-b54165203/" target="_blank">Yann Fabel</a>,
                                <a href="https://www.linkedin.com/in/bijan-nouri-664023218/" target="_blank">Bijan Nouri</a>,
                                Stefan Wilbert,
                                Niklas Blum,
                                <strong>Dominik Schnaus</strong>,
                                <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/" target="_blank">Rudolph Triebel</a>
                                Luis F. Zarzalejo, 
                                Enrique Ugedo, 
                                Julia Kowalski,
                                Robert Pitz-Paal
                                <br>
                                <b>Solar RRL</b>, 2024
                                <br>
                                <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/solr.202300808" target="_blank">paper</a>
                                <p></p>
                                <p>
                                    We introduce a transformer model for solar irradiance nowcasting from all-sky imagers.
                                </p>
                            </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='static/images/schnaus2023learning.png' width=100%>
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                    <a href="https://proceedings.mlr.press/v202/schnaus23a">
                                        <span class="papertitle">Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</span>
                                    </a>
                                    <br>
                                    <strong>Dominik Schnaus</strong>,
                                    <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/" target="_blank">Jongseok Lee</a>,
                                    <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">Daniel Cremers</a>,
                                    <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/" target="_blank">Rudolph Triebel</a>
                                    <br>
                                    <b>ICML</b>, 2023
                                    <br>
                                    <a href="https://proceedings.mlr.press/v202/schnaus23a" target="_blank">paper</a>
                                    /
                                    <a href="https://arxiv.org/abs/2307.07753" target="_blank">arXiv</a>
                                    /
                                    <a href="https://icml.cc/media/PosterPDFs/ICML%202023/23901.png?t=1689841529.0378458" target="_blank">poster</a>
                                    /
                                    <a href="https://github.com/DLR-RM/BPNN" target="_blank">code</a>
                                    <p></p>
                                    <p>
                                        We use Laplace approximation to learn expressive priors for neural networks. This improves the uncertainty estimation and PAC-Bayes generalization bounds.
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <img src='static/images/schnaus2021bayesian.png' width=100%>
                                    </div>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:top">
                                    <a href="http://bayesiandeeplearning.org/2021/papers/33.pdf">
                                        <span class="papertitle">Kronecker-Factored Optimal Curvature</span>
                                    </a>
                                    <br>
                                    <strong>Dominik Schnaus</strong>,
                                    <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/" target="_blank">Jongseok Lee</a>,
                                    <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">Daniel Cremers</a>,
                                    <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/" target="_blank">Rudolph Triebel</a>
                                    <br>
                                    <b>BDL at NeurIPS</b>, 2021
                                    <br>
                                    <a href="http://bayesiandeeplearning.org/2021/papers/33.pdf" target="_blank">paper</a>
                                    /
                                    <a href="https://github.com/DLR-RM/BPNN/blob/main/poster_kfoc.pdf" target="_blank">poster</a>
                                    /
                                    <a href="https://github.com/DLR-RM/BPNN" target="_blank">code</a>
                                    <p></p>
                                    <p>
                                        Leveraging the power method for finding better Kronecker-factored approximations of the Fisher Information matrix.
                                    </p>
                                </td>
                            </tr>
                </tbody>
            </table>
                </td>
            </tr>
        </tbody>
    </table>

</body>

</html>